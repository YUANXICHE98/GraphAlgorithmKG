"""
åŸºäºæœ¬ä½“Schemaçš„é¢†åŸŸè¯†åˆ«ç³»ç»Ÿ
ç»“åˆ document + seed_knowledge + ontology + LLM è¿›è¡Œæ™ºèƒ½è¯†åˆ«
"""

import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

from ontology.managers.dynamic_schema import DynamicOntologyManager

@dataclass
class SchemaDetectionResult:
    """Schemaæ£€æµ‹ç»“æœ"""
    schema_file: str
    confidence: float
    evidence: List[str]
    method: str  # 'ontology', 'seed_knowledge', 'document', 'llm'

class SchemaDetector:
    """åŸºäºæœ¬ä½“Schemaçš„é¢†åŸŸæ£€æµ‹å™¨"""
    
    def __init__(self, schema_dir: str = "ontology/schemas/spatiotemporal"):
        self.schema_dir = Path(schema_dir)
        self.available_schemas = self._discover_schemas()
        self.ontology_managers = {}
        
        # åŠ è½½æ‰€æœ‰å¯ç”¨çš„Schema
        self._load_all_schemas()
    
    def _discover_schemas(self) -> List[str]:
        """å‘ç°å¯ç”¨çš„Schemaæ–‡ä»¶"""
        schema_files = []

        # æ·»åŠ é€šç”¨æœ¬ä½“Schema
        schema_files.append("../schemas/general/schema_config.yaml")  # é€šç”¨æœ¬ä½“

        # æ·»åŠ æ—¶ç©ºæœ¬ä½“Schema
        if self.schema_dir.exists():
            for file_path in self.schema_dir.glob("*.yaml"):
                schema_files.append(file_path.name)

        return schema_files
    
    def _load_all_schemas(self):
        """åŠ è½½æ‰€æœ‰Schema"""
        for schema_file in self.available_schemas:
            try:
                if schema_file.startswith("../"):
                    schema_path = str(Path("ontology") / schema_file[3:])
                else:
                    schema_path = str(self.schema_dir / schema_file)
                
                manager = DynamicOntologyManager(schema_path)
                self.ontology_managers[schema_file] = manager
                print(f"âœ… åŠ è½½Schema: {schema_file}")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½Schemaå¤±è´¥ {schema_file}: {e}")
    
    def detect_schema(self, document_text: str, seed_knowledge: List[Dict] = None,
                     use_llm: bool = True) -> List[SchemaDetectionResult]:
        """
        ç»¼åˆæ£€æµ‹æœ€é€‚åˆçš„Schema

        Args:
            document_text: æ–‡æ¡£æ–‡æœ¬
            seed_knowledge: ç§å­çŸ¥è¯†ï¼ˆä¸‰å…ƒç»„åˆ—è¡¨ï¼‰
            use_llm: æ˜¯å¦ä½¿ç”¨LLMè¾…åŠ©å†³ç­–

        Returns:
            æŒ‰ç½®ä¿¡åº¦æ’åºçš„Schemaæ£€æµ‹ç»“æœ
        """
        results = []

        for schema_file, manager in self.ontology_managers.items():
            # æ–¹æ³•1ï¼šåŸºäºæœ¬ä½“å®ä½“ç±»å‹åŒ¹é…
            ontology_score, ontology_evidence = self._ontology_based_detection(
                document_text, manager
            )

            # æ–¹æ³•2ï¼šåŸºäºç§å­çŸ¥è¯†åŒ¹é…
            seed_score, seed_evidence = self._seed_knowledge_detection(
                seed_knowledge, manager
            ) if seed_knowledge else (0.0, [])

            # æ–¹æ³•3ï¼šåŸºäºæ–‡æ¡£ç»“æ„ç‰¹å¾
            document_score, document_evidence = self._document_structure_detection(
                document_text, manager
            )

            # ç»¼åˆè¯„åˆ†
            final_score = (
                0.4 * ontology_score +      # æœ¬ä½“åŒ¹é…æƒé‡æœ€é«˜
                0.3 * seed_score +          # ç§å­çŸ¥è¯†åŒ¹é…
                0.3 * document_score        # æ–‡æ¡£ç»“æ„åŒ¹é…
            )

            if final_score > 0.05:  # é™ä½æœ€ä½é˜ˆå€¼
                all_evidence = ontology_evidence + seed_evidence + document_evidence
                results.append(SchemaDetectionResult(
                    schema_file=schema_file,
                    confidence=final_score,
                    evidence=all_evidence[:5],  # æœ€å¤š5ä¸ªè¯æ®
                    method='hybrid'
                ))

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        results.sort(key=lambda x: x.confidence, reverse=True)

        # LLMè¾…åŠ©å†³ç­–ï¼šå½“å‰ä¸¤åç½®ä¿¡åº¦ç›¸è¿‘æ—¶
        if use_llm and len(results) >= 2:
            top1, top2 = results[0], results[1]
            confidence_diff = top1.confidence - top2.confidence

            if confidence_diff < 0.1:  # ç½®ä¿¡åº¦å·®å¼‚å°äº10%
                print(f"ğŸ¤– ç½®ä¿¡åº¦ç›¸è¿‘({confidence_diff:.3f})ï¼Œå¯ç”¨LLMè¾…åŠ©å†³ç­–...")
                llm_result = self._llm_schema_decision(document_text, [top1, top2])
                if llm_result:
                    # æ›´æ–°LLMé€‰æ‹©çš„Schemaç½®ä¿¡åº¦
                    for result in results:
                        if result.schema_file == llm_result:
                            result.confidence += 0.1  # ç»™LLMé€‰æ‹©çš„SchemaåŠ åˆ†
                            result.method = 'llm_assisted'
                            break

                    # é‡æ–°æ’åº
                    results.sort(key=lambda x: x.confidence, reverse=True)

        return results
    
    def _ontology_based_detection(self, text: str, manager: DynamicOntologyManager) -> Tuple[float, List[str]]:
        """åŸºäºæœ¬ä½“å®ä½“ç±»å‹çš„æ£€æµ‹"""
        text_lower = text.lower()
        matched_entities = []
        matched_keywords = []
        
        # æ£€æŸ¥å®ä½“ç±»å‹çš„å…³é”®è¯å’Œæ¨¡å¼
        for entity_type, config in manager.entity_types.items():
            # æ£€æŸ¥å…³é”®è¯
            if hasattr(config, 'keywords'):
                for keyword in config.keywords:
                    if keyword.lower() in text_lower:
                        matched_keywords.append(f"{entity_type}:{keyword}")
            
            # æ£€æŸ¥ç¤ºä¾‹å®ä½“
            if hasattr(config, 'examples'):
                for example in config.examples:
                    if example.lower() in text_lower:
                        matched_entities.append(f"{entity_type}:{example}")
        
        # è®¡ç®—å¾—åˆ†
        total_types = len(manager.entity_types)
        entity_score = len(matched_entities) / max(total_types * 2, 1)  # æ¯ä¸ªç±»å‹æœŸæœ›2ä¸ªå®ä½“
        keyword_score = len(matched_keywords) / max(total_types * 3, 1)  # æ¯ä¸ªç±»å‹æœŸæœ›3ä¸ªå…³é”®è¯
        
        final_score = min((entity_score + keyword_score) / 2, 1.0)
        evidence = matched_entities + matched_keywords
        
        return final_score, evidence
    
    def _seed_knowledge_detection(self, seed_knowledge: List[Dict], manager: DynamicOntologyManager) -> Tuple[float, List[str]]:
        """åŸºäºç§å­çŸ¥è¯†çš„æ£€æµ‹"""
        if not seed_knowledge:
            return 0.0, []
        
        matched_relations = []
        matched_entities = []
        
        # æ£€æŸ¥ç§å­çŸ¥è¯†ä¸­çš„å…³ç³»ç±»å‹
        for triple in seed_knowledge:
            predicate = triple.get('predicate', '')
            if predicate in manager.relation_types:
                matched_relations.append(f"å…³ç³»:{predicate}")
            
            # æ£€æŸ¥å®ä½“æ˜¯å¦ç¬¦åˆæœ¬ä½“å®šä¹‰
            subject = triple.get('subject', '')
            obj = triple.get('object', '')
            
            for entity_name in [subject, obj]:
                if entity_name:
                    inferred_type = self._infer_entity_type_from_schema(entity_name, manager)
                    if inferred_type:
                        matched_entities.append(f"å®ä½“:{entity_name}({inferred_type})")
        
        # è®¡ç®—å¾—åˆ†
        total_relations = len(manager.relation_types)
        relation_score = len(set(matched_relations)) / max(total_relations, 1)
        entity_score = len(matched_entities) / max(len(seed_knowledge) * 2, 1)
        
        final_score = min((relation_score + entity_score) / 2, 1.0)
        evidence = list(set(matched_relations + matched_entities))
        
        return final_score, evidence
    
    def _document_structure_detection(self, text: str, manager: DynamicOntologyManager) -> Tuple[float, List[str]]:
        """åŸºäºæ–‡æ¡£ç»“æ„ç‰¹å¾çš„æ£€æµ‹"""
        evidence = []
        score = 0.0
        
        # æ£€æŸ¥æ–‡æ¡£ä¸­çš„ç»“æ„åŒ–æ¨¡å¼
        # ä¾‹å¦‚ï¼šDoDAFçš„OV-1, SV-1æ¨¡å¼ï¼Œæ—¶ç©ºæœ¬ä½“çš„æ—¶é—´è¡¨è¾¾ç­‰
        
        # æå–å¯èƒ½çš„ç»“æ„åŒ–å®ä½“
        structured_entities = re.findall(r'\b[A-Z]{2,3}-\d+\b', text)  # OV-1, SV-1ç­‰
        time_expressions = re.findall(r'\d{4}-\d{2}-\d{2}', text)      # æ—¶é—´è¡¨è¾¾
        
        structure_matches = 0
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…Schemaä¸­å®šä¹‰çš„æ¨¡å¼
        for entity_type, config in manager.entity_types.items():
            if hasattr(config, 'patterns'):
                for pattern in config.patterns:
                    try:
                        matches = re.findall(pattern, text, re.IGNORECASE)
                        if matches:
                            structure_matches += len(matches)
                            evidence.append(f"æ¨¡å¼:{entity_type}({len(matches)}ä¸ª)")
                    except re.error:
                        continue
        
        # åŸºäºç»“æ„åŒ–åŒ¹é…è®¡ç®—å¾—åˆ†
        if structure_matches > 0:
            score = min(structure_matches / 10.0, 1.0)  # æ¯10ä¸ªåŒ¹é…å¾—1åˆ†
        
        return score, evidence
    
    def _infer_entity_type_from_schema(self, entity_name: str, manager: DynamicOntologyManager) -> Optional[str]:
        """ä»Schemaæ¨æ–­å®ä½“ç±»å‹"""
        entity_lower = entity_name.lower()
        
        for entity_type, config in manager.entity_types.items():
            # æ£€æŸ¥å…³é”®è¯
            if hasattr(config, 'keywords'):
                for keyword in config.keywords:
                    if keyword.lower() in entity_lower:
                        return entity_type
            
            # æ£€æŸ¥æ¨¡å¼
            if hasattr(config, 'patterns'):
                for pattern in config.patterns:
                    try:
                        if re.match(pattern, entity_name, re.IGNORECASE):
                            return entity_type
                    except re.error:
                        continue
        
        return None
    
    def get_best_schema(self, document_text: str, seed_knowledge: List[Dict] = None) -> Optional[str]:
        """è·å–æœ€ä½³åŒ¹é…çš„Schema"""
        results = self.detect_schema(document_text, seed_knowledge)

        if results and results[0].confidence > 0.05:  # è¿›ä¸€æ­¥é™ä½æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼
            return results[0].schema_file

        return None
    
    def get_schema_suggestions(self, document_text: str, seed_knowledge: List[Dict] = None) -> Dict[str, str]:
        """è·å–Schemaå»ºè®®å’Œç†ç”±"""
        results = self.detect_schema(document_text, seed_knowledge)
        suggestions = {}
        
        for result in results:
            if result.confidence > 0.1:
                reason = f"ç½®ä¿¡åº¦: {result.confidence:.2f}, è¯æ®: {', '.join(result.evidence[:2])}"
                suggestions[result.schema_file] = reason
        
        return suggestions

    def _llm_schema_decision(self, document_text: str, candidate_schemas: List[SchemaDetectionResult]) -> Optional[str]:
        """LLMè¾…åŠ©Schemaå†³ç­–"""
        try:
            from pipeline.llm_client import LLMClient

            llm_client = LLMClient()

            # æ„å»ºå€™é€‰Schemaæè¿°
            schema_descriptions = []
            for result in candidate_schemas:
                manager = self.ontology_managers[result.schema_file]
                schema_info = getattr(manager, 'metadata', {})
                description = schema_info.get('description', f'Schema: {result.schema_file}')

                schema_descriptions.append(f"""
Schema: {result.schema_file}
æè¿°: {description}
ç½®ä¿¡åº¦: {result.confidence:.3f}
è¯æ®: {', '.join(result.evidence)}
""")

            # LLM Prompt
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æœ¬ä½“é€‰æ‹©ä¸“å®¶ã€‚è¯·æ ¹æ®ç»™å®šçš„æ–‡æ¡£å†…å®¹ï¼Œä»å€™é€‰Schemaä¸­é€‰æ‹©æœ€é€‚åˆçš„ä¸€ä¸ªã€‚

æ–‡æ¡£å†…å®¹ï¼š
{document_text[:1000]}...

å€™é€‰Schemaï¼š
{''.join(schema_descriptions)}

è¯·åˆ†ææ–‡æ¡£çš„ä¸»è¦å†…å®¹å’Œç»“æ„ç‰¹å¾ï¼Œé€‰æ‹©æœ€é€‚åˆçš„Schemaã€‚åªéœ€è¦å›ç­”Schemaæ–‡ä»¶åï¼Œä¸éœ€è¦è§£é‡Šã€‚

æœ€é€‚åˆçš„Schemaæ˜¯ï¼š"""

            response = llm_client.generate_response(prompt, max_tokens=50)

            # æå–Schemaæ–‡ä»¶å
            for result in candidate_schemas:
                if result.schema_file in response:
                    print(f"ğŸ¯ LLMé€‰æ‹©: {result.schema_file}")
                    return result.schema_file

            return None

        except Exception as e:
            print(f"âš ï¸ LLMè¾…åŠ©å†³ç­–å¤±è´¥: {e}")
            return None

# å…¨å±€Schemaæ£€æµ‹å™¨å®ä¾‹
schema_detector = SchemaDetector()
