"""
æ··åˆä¸‰å…ƒç»„æŠ½å–å™¨
åè°ƒè§„åˆ™æŠ½å–å’ŒLLMæŠ½å–ï¼Œå®ç°æ­£ç¡®çš„æŠ½å–æµç¨‹ï¼š
è§„åˆ™æŠ½å– â†’ è§„åˆ™å¤±è´¥æ—¶ä½¿ç”¨LLMæŠ½å–
"""

import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from pipeline.rule_based_triple_extractor import RuleBasedTripleExtractor, TripleExtractionResult
from pipeline.llm_client import LLMClient
from ontology.managers.dynamic_schema import DynamicOntologyManager

@dataclass
class HybridExtractionResult:
    """æ··åˆæŠ½å–ç»“æœ"""
    triples: List[Dict[str, Any]]
    rule_count: int
    llm_count: int
    total_time: float
    methods_used: List[str]

class HybridTripleExtractor:
    """æ··åˆä¸‰å…ƒç»„æŠ½å–å™¨"""
    
    def __init__(self, ontology_manager: DynamicOntologyManager):
        self.ontology_manager = ontology_manager
        self.rule_extractor = RuleBasedTripleExtractor(ontology_manager)
        self.llm_client = LLMClient()
        
        # é…ç½®å‚æ•°
        self.min_rule_confidence = 0.6  # è§„åˆ™æŠ½å–æœ€ä½ç½®ä¿¡åº¦
        self.min_rule_count = 3  # è§„åˆ™æŠ½å–æœ€å°‘ä¸‰å…ƒç»„æ•°é‡
        self.use_llm_fallback = True  # æ˜¯å¦å¯ç”¨LLMå…œåº•
    
    def extract_triples(self, text: str) -> HybridExtractionResult:
        """
        æ··åˆæŠ½å–ä¸‰å…ƒç»„
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ··åˆæŠ½å–ç»“æœ
        """
        start_time = time.time()
        methods_used = []
        
        print(f"\nğŸ”„ æ··åˆæŠ½å–å™¨å¼€å§‹å¤„ç†")
        print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print("=" * 60)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šè§„åˆ™æŠ½å–
        print(f"\nğŸ”§ é˜¶æ®µ1: è§„åˆ™æŠ½å–")
        rule_results = self.rule_extractor.extract_triples(text)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        rule_triples = []
        for result in rule_results:
            triple = {
                "subject": result.subject,
                "predicate": result.predicate,
                "object": result.object,
                "confidence": result.confidence,
                "method": result.method,
                "evidence": result.evidence
            }
            rule_triples.append(triple)
        
        print(f"   ğŸ“Š è§„åˆ™æŠ½å–ç»“æœ: {len(rule_triples)} ä¸ªä¸‰å…ƒç»„")
        
        # åˆ†æè§„åˆ™æŠ½å–è´¨é‡
        high_confidence_rules = [t for t in rule_triples if t["confidence"] >= self.min_rule_confidence]
        rule_quality_score = len(high_confidence_rules) / max(len(rule_triples), 1)
        
        print(f"   ğŸ“ˆ é«˜ç½®ä¿¡åº¦ä¸‰å…ƒç»„: {len(high_confidence_rules)} ä¸ª")
        print(f"   ğŸ¯ è§„åˆ™è´¨é‡åˆ†æ•°: {rule_quality_score:.2f}")
        
        methods_used.append("rule_extraction")
        
        # ç¬¬äºŒé˜¶æ®µï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦LLMå…œåº•
        need_llm_fallback = self._should_use_llm_fallback(rule_triples, text)
        
        llm_triples = []
        if need_llm_fallback and self.use_llm_fallback:
            print(f"\nğŸ¤– é˜¶æ®µ2: LLMå…œåº•æŠ½å–")
            print(f"   ğŸ” è§¦å‘åŸå› : {self._get_fallback_reason(rule_triples, text)}")
            
            llm_triples = self._llm_extract_triples(text)
            print(f"   ğŸ“Š LLMæŠ½å–ç»“æœ: {len(llm_triples)} ä¸ªä¸‰å…ƒç»„")
            methods_used.append("llm_extraction")
        else:
            print(f"\nâœ… è§„åˆ™æŠ½å–å……åˆ†ï¼Œæ— éœ€LLMå…œåº•")
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šç»“æœåˆå¹¶å’Œå»é‡
        print(f"\nğŸ”„ é˜¶æ®µ3: ç»“æœåˆå¹¶")
        final_triples = self._merge_and_deduplicate(rule_triples, llm_triples)
        
        total_time = time.time() - start_time
        
        print(f"   ğŸ“Š æœ€ç»ˆç»“æœ: {len(final_triples)} ä¸ªä¸‰å…ƒç»„")
        print(f"   â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s")
        print("=" * 60)
        
        return HybridExtractionResult(
            triples=final_triples,
            rule_count=len(rule_triples),
            llm_count=len(llm_triples),
            total_time=total_time,
            methods_used=methods_used
        )
    
    def _should_use_llm_fallback(self, rule_triples: List[Dict[str, Any]], text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦LLMå…œåº•"""
        # æ¡ä»¶1: è§„åˆ™æŠ½å–æ•°é‡ä¸è¶³
        if len(rule_triples) < self.min_rule_count:
            return True
        
        # æ¡ä»¶2: é«˜ç½®ä¿¡åº¦ä¸‰å…ƒç»„æ¯”ä¾‹è¿‡ä½
        high_confidence_count = sum(1 for t in rule_triples if t["confidence"] >= self.min_rule_confidence)
        if high_confidence_count / len(rule_triples) < 0.5:
            return True
        
        # æ¡ä»¶3: æ–‡æœ¬å¤æ‚åº¦é«˜ä½†æŠ½å–ç»“æœå°‘
        text_complexity = self._calculate_text_complexity(text)
        expected_triples = max(3, text_complexity // 100)  # æ¯100å­—ç¬¦æœŸæœ›è‡³å°‘1ä¸ªä¸‰å…ƒç»„
        
        if len(rule_triples) < expected_triples * 0.5:
            return True
        
        return False
    
    def _get_fallback_reason(self, rule_triples: List[Dict[str, Any]], text: str) -> str:
        """è·å–LLMå…œåº•çš„åŸå› """
        reasons = []
        
        if len(rule_triples) < self.min_rule_count:
            reasons.append(f"ä¸‰å…ƒç»„æ•°é‡ä¸è¶³({len(rule_triples)}<{self.min_rule_count})")
        
        high_confidence_count = sum(1 for t in rule_triples if t["confidence"] >= self.min_rule_confidence)
        if len(rule_triples) > 0 and high_confidence_count / len(rule_triples) < 0.5:
            reasons.append(f"é«˜ç½®ä¿¡åº¦æ¯”ä¾‹è¿‡ä½({high_confidence_count}/{len(rule_triples)})")
        
        text_complexity = self._calculate_text_complexity(text)
        expected_triples = max(3, text_complexity // 100)
        if len(rule_triples) < expected_triples * 0.5:
            reasons.append(f"æŠ½å–å¯†åº¦è¿‡ä½({len(rule_triples)}<{expected_triples*0.5:.1f})")
        
        return "; ".join(reasons) if reasons else "æœªçŸ¥åŸå› "
    
    def _calculate_text_complexity(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬å¤æ‚åº¦"""
        # ç®€å•çš„å¤æ‚åº¦è®¡ç®—ï¼šå­—ç¬¦æ•° + å¥å­æ•° + å®ä½“æ•°ä¼°è®¡
        char_count = len(text)
        sentence_count = len([s for s in text.split('.') if len(s.strip()) > 5])
        entity_estimate = len([w for w in text.split() if w[0].isupper()]) if text else 0
        
        return char_count + sentence_count * 10 + entity_estimate * 5
    
    def _llm_extract_triples(self, text: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨LLMæŠ½å–ä¸‰å…ƒç»„"""
        schema_info = {
            'name': self.ontology_manager.metadata.get('name', 'æœªçŸ¥Schema'),
            'entity_types': self.ontology_manager.entity_types,
            'relation_types': self.ontology_manager.relation_types
        }
        
        # è°ƒç”¨LLMæŠ½å–
        llm_triples = self.llm_client.extract_triples(text, schema_info)
        
        # æ ‡è®°LLMæ¥æº
        for triple in llm_triples:
            if "method" not in triple:
                triple["method"] = "llm_extraction"
            if "evidence" not in triple:
                triple["evidence"] = "LLM generated"
        
        return llm_triples
    
    def _merge_and_deduplicate(self, rule_triples: List[Dict[str, Any]], 
                              llm_triples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œå»é‡ä¸‰å…ƒç»„"""
        all_triples = rule_triples + llm_triples
        
        if not all_triples:
            return []
        
        # ç®€å•å»é‡ï¼šåŸºäºä¸»è¯­-è°“è¯­-å®¾è¯­çš„ç»„åˆ
        seen_triples = set()
        unique_triples = []
        
        for triple in all_triples:
            triple_key = (
                triple["subject"].lower().strip(),
                triple["predicate"].lower().strip(),
                triple["object"].lower().strip()
            )
            
            if triple_key not in seen_triples:
                seen_triples.add(triple_key)
                unique_triples.append(triple)
            else:
                # å¦‚æœé‡å¤ï¼Œä¿ç•™ç½®ä¿¡åº¦æ›´é«˜çš„
                for i, existing in enumerate(unique_triples):
                    existing_key = (
                        existing["subject"].lower().strip(),
                        existing["predicate"].lower().strip(),
                        existing["object"].lower().strip()
                    )
                    if existing_key == triple_key:
                        if triple.get("confidence", 0) > existing.get("confidence", 0):
                            unique_triples[i] = triple
                        break
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        unique_triples.sort(key=lambda x: x.get("confidence", 0), reverse=True)
        
        print(f"   ğŸ”„ å»é‡å‰: {len(all_triples)} ä¸ªï¼Œå»é‡å: {len(unique_triples)} ä¸ª")
        
        return unique_triples
    
    def get_extraction_statistics(self, result: HybridExtractionResult) -> Dict[str, Any]:
        """è·å–æŠ½å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_triples": len(result.triples),
            "rule_triples": result.rule_count,
            "llm_triples": result.llm_count,
            "rule_ratio": result.rule_count / max(len(result.triples), 1),
            "llm_ratio": result.llm_count / max(len(result.triples), 1),
            "methods_used": result.methods_used,
            "processing_time": result.total_time,
            "avg_confidence": sum(t.get("confidence", 0) for t in result.triples) / max(len(result.triples), 1)
        }
        
        # æŒ‰æ–¹æ³•åˆ†ç»„ç»Ÿè®¡
        method_stats = {}
        for triple in result.triples:
            method = triple.get("method", "unknown")
            if method not in method_stats:
                method_stats[method] = {"count": 0, "avg_confidence": 0}
            method_stats[method]["count"] += 1
        
        # è®¡ç®—å„æ–¹æ³•çš„å¹³å‡ç½®ä¿¡åº¦
        for method in method_stats:
            method_triples = [t for t in result.triples if t.get("method") == method]
            if method_triples:
                method_stats[method]["avg_confidence"] = sum(t.get("confidence", 0) for t in method_triples) / len(method_triples)
        
        stats["method_breakdown"] = method_stats
        
        return stats
