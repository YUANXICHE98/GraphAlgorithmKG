"""
åŸºäºè§„åˆ™çš„ä¸‰å…ƒç»„æŠ½å–å™¨
æ™ºèƒ½æ¨æ–­å±‚çš„æ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡è§„åˆ™å’Œæ¨¡å¼è¯†åˆ«ç›´æ¥æŠ½å–ä¸‰å…ƒç»„
"""

import re
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

from ontology.managers.dynamic_schema import DynamicOntologyManager
from pipeline.enhanced_entity_inferer import EnhancedEntityTypeInferer

@dataclass
class TripleExtractionResult:
    """ä¸‰å…ƒç»„æŠ½å–ç»“æœ"""
    subject: str
    predicate: str
    object: str
    confidence: float
    method: str
    evidence: str

class RuleBasedTripleExtractor:
    """åŸºäºè§„åˆ™çš„ä¸‰å…ƒç»„æŠ½å–å™¨"""
    
    def __init__(self, ontology_manager: DynamicOntologyManager):
        self.ontology_manager = ontology_manager
        self.entity_inferer = EnhancedEntityTypeInferer()
        self.entity_inferer.ontology_manager = ontology_manager
        
        # é¢„ç¼–è¯‘çš„æ¨¡å¼
        self._compile_patterns()
    
    def _compile_patterns(self):
        """ç¼–è¯‘æŠ½å–æ¨¡å¼"""
        self.patterns = {
            # å®ä¾‹å…³ç³»æ¨¡å¼
            'instance_patterns': [
                r'(\w+)\s+æ˜¯\s+(\w+)',
                r'(\w+)\s+å±äº\s+(\w+)',
                r'(\w+)\s+is\s+a\s+(\w+)',
                r'(\w+)\s+is\s+an\s+(\w+)',
                r'(\w+)\s+is\s+instance\s+of\s+(\w+)',
            ],
            
            # æ—¶é—´å…³ç³»æ¨¡å¼
            'temporal_patterns': [
                r'(\w+)\s+å¼€å§‹æ—¶é—´\s*[:ï¼š]\s*([0-9\-:\s]+)',
                r'(\w+)\s+ç»“æŸæ—¶é—´\s*[:ï¼š]\s*([0-9\-:\s]+)',
                r'(\w+)\s+æŒç»­æ—¶é—´\s*[:ï¼š]\s*([0-9]+[å°æ—¶å¤©åˆ†é’Ÿ])',
                r'(\w+)\s+å‘ç”Ÿåœ¨\s+([0-9\-:\s]+)',
                r'(\w+)\s+before\s+(\w+)',
                r'(\w+)\s+after\s+(\w+)',
            ],
            
            # ç©ºé—´å…³ç³»æ¨¡å¼
            'spatial_patterns': [
                r'(\w+)\s+ä½äº\s+(\w+)',
                r'(\w+)\s+åœ¨\s+(\w+)',
                r'(\w+)\s+located\s+at\s+(\w+)',
                r'(\w+)\s+contains\s+(\w+)',
                r'(\w+)\s+åŒ…å«\s+(\w+)',
            ],
            
            # DO-DA-Få…³ç³»æ¨¡å¼
            'dodaf_patterns': [
                r'(\w+)\s+æ¡ä»¶\s*[:ï¼š]\s*([^,ï¼Œã€‚.]+)',
                r'(\w+)\s+ç»“æœ\s*[:ï¼š]\s*([^,ï¼Œã€‚.]+)',
                r'(\w+)\s+å¯¼è‡´\s+(\w+)',
                r'(\w+)\s+causes\s+(\w+)',
                r'(\w+)\s+results\s+in\s+(\w+)',
                r'(\w+)\s+has\s+condition\s+([^,ï¼Œã€‚.]+)',
            ],
            
            # æ¶æ„å…³ç³»æ¨¡å¼
            'architecture_patterns': [
                r'(\w+)\s+åŒ…å«\s+(\w+)',
                r'(\w+)\s+supports\s+(\w+)',
                r'(\w+)\s+implements\s+(\w+)',
                r'(\w+)\s+uses\s+(\w+)',
            ]
        }
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.compiled_patterns = {}
        for category, patterns in self.patterns.items():
            self.compiled_patterns[category] = [re.compile(pattern, re.IGNORECASE) for pattern in patterns]
    
    def extract_triples(self, text: str) -> List[TripleExtractionResult]:
        """
        ä»æ–‡æœ¬ä¸­æŠ½å–ä¸‰å…ƒç»„
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            ä¸‰å…ƒç»„æŠ½å–ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ”§ è§„åˆ™æŠ½å–å™¨å¼€å§‹å¤„ç†æ–‡æœ¬ï¼Œé•¿åº¦: {len(text)}")
        
        triples = []
        
        # 1. å®ä¾‹å…³ç³»æŠ½å–
        instance_triples = self._extract_instance_relations(text)
        triples.extend(instance_triples)
        
        # 2. æ—¶é—´å…³ç³»æŠ½å–
        temporal_triples = self._extract_temporal_relations(text)
        triples.extend(temporal_triples)
        
        # 3. ç©ºé—´å…³ç³»æŠ½å–
        spatial_triples = self._extract_spatial_relations(text)
        triples.extend(spatial_triples)
        
        # 4. DO-DA-Få…³ç³»æŠ½å–
        dodaf_triples = self._extract_dodaf_relations(text)
        triples.extend(dodaf_triples)
        
        # 5. æ¶æ„å…³ç³»æŠ½å–
        arch_triples = self._extract_architecture_relations(text)
        triples.extend(arch_triples)
        
        # 6. åŸºäºå®ä½“æ¨æ–­çš„å…³ç³»å‘ç°
        inferred_triples = self._infer_relations_from_entities(text)
        triples.extend(inferred_triples)
        
        print(f"ğŸ”§ è§„åˆ™æŠ½å–å®Œæˆï¼Œå…±æŠ½å– {len(triples)} ä¸ªä¸‰å…ƒç»„")
        
        return triples
    
    def _extract_instance_relations(self, text: str) -> List[TripleExtractionResult]:
        """æŠ½å–å®ä¾‹å…³ç³»"""
        triples = []
        
        for pattern in self.compiled_patterns['instance_patterns']:
            matches = pattern.findall(text)
            for match in matches:
                subject, obj = match
                
                # éªŒè¯å®ä½“ç±»å‹
                subject_type = self.entity_inferer.infer_entity_type(subject)
                object_type = self.entity_inferer.infer_entity_type(obj)
                
                if subject_type.confidence > 0.5 and object_type.confidence > 0.5:
                    triple = TripleExtractionResult(
                        subject=subject,
                        predicate="is_instance_of",
                        object=obj,
                        confidence=min(subject_type.confidence, object_type.confidence),
                        method="rule_pattern",
                        evidence=f"Pattern match: {pattern.pattern}"
                    )
                    triples.append(triple)
        
        return triples
    
    def _extract_temporal_relations(self, text: str) -> List[TripleExtractionResult]:
        """æŠ½å–æ—¶é—´å…³ç³»"""
        triples = []
        
        # å¼€å§‹æ—¶é—´æ¨¡å¼
        start_time_patterns = [
            r'(\w+)[^0-9]*å¼€å§‹æ—¶é—´[^0-9]*([0-9\-:\s]+)',
            r'(\w+)[^0-9]*å‘ç”Ÿåœ¨[^0-9]*([0-9\-:\s]+)',
        ]
        
        for pattern_str in start_time_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, time_str = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="hasStartTime",
                    object=time_str.strip(),
                    confidence=0.8,
                    method="temporal_pattern",
                    evidence=f"Time pattern: {pattern_str}"
                )
                triples.append(triple)
        
        # æŒç»­æ—¶é—´æ¨¡å¼
        duration_patterns = [
            r'(\w+)[^0-9]*æŒç»­æ—¶é—´[^0-9]*([0-9]+[å°æ—¶å¤©åˆ†é’Ÿ])',
            r'(\w+)[^0-9]*æŒç»­[^0-9]*([0-9]+[å°æ—¶å¤©åˆ†é’Ÿ])',
        ]
        
        for pattern_str in duration_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, duration = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="hasDuration",
                    object=duration.strip(),
                    confidence=0.8,
                    method="temporal_pattern",
                    evidence=f"Duration pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_spatial_relations(self, text: str) -> List[TripleExtractionResult]:
        """æŠ½å–ç©ºé—´å…³ç³»"""
        triples = []
        
        # ä½ç½®å…³ç³»æ¨¡å¼
        location_patterns = [
            r'(\w+)[^a-zA-Z]*ä½äº[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*åœ¨[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in location_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, location = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="locatedAt",
                    object=location.strip(),
                    confidence=0.8,
                    method="spatial_pattern",
                    evidence=f"Location pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_dodaf_relations(self, text: str) -> List[TripleExtractionResult]:
        """æŠ½å–DO-DA-Få…³ç³»"""
        triples = []
        
        # æ¡ä»¶å…³ç³»æ¨¡å¼
        condition_patterns = [
            r'(\w+)[^>]*æ¡ä»¶[^>]*[:ï¼š]\s*([^,ï¼Œã€‚.]+)',
            r'(\w+)[^>]*when[^>]*([^,ï¼Œã€‚.]+)',
        ]
        
        for pattern_str in condition_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                action, condition = match
                
                triple = TripleExtractionResult(
                    subject=action.strip(),
                    predicate="hasCondition",
                    object=condition.strip(),
                    confidence=0.7,
                    method="dodaf_pattern",
                    evidence=f"Condition pattern: {pattern_str}"
                )
                triples.append(triple)
        
        # ç»“æœå…³ç³»æ¨¡å¼
        result_patterns = [
            r'(\w+)[^a-zA-Z]*ç»“æœ[^a-zA-Z]*[:ï¼š]\s*([^,ï¼Œã€‚.]+)',
            r'(\w+)[^a-zA-Z]*å¯¼è‡´[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*results\s+in[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in result_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                action, result = match
                
                triple = TripleExtractionResult(
                    subject=action.strip(),
                    predicate="resultsIn",
                    object=result.strip(),
                    confidence=0.7,
                    method="dodaf_pattern",
                    evidence=f"Result pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_architecture_relations(self, text: str) -> List[TripleExtractionResult]:
        """æŠ½å–æ¶æ„å…³ç³»"""
        triples = []
        
        # åŒ…å«å…³ç³»æ¨¡å¼
        contains_patterns = [
            r'(\w+)[^a-zA-Z]*åŒ…å«[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*contains[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in contains_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                container, contained = match
                
                triple = TripleExtractionResult(
                    subject=container.strip(),
                    predicate="contains",
                    object=contained.strip(),
                    confidence=0.7,
                    method="architecture_pattern",
                    evidence=f"Contains pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _infer_relations_from_entities(self, text: str) -> List[TripleExtractionResult]:
        """åŸºäºå®ä½“æ¨æ–­å…³ç³»"""
        triples = []
        
        # ç®€å•çš„å…±ç°å…³ç³»æ¨æ–­
        sentences = re.split(r'[ã€‚.!ï¼?ï¼Ÿ]', text)
        
        for sentence in sentences:
            if len(sentence.strip()) < 10:
                continue
            
            # æå–å¥å­ä¸­çš„å®ä½“
            entities = self._extract_entities_from_sentence(sentence)
            
            if len(entities) >= 2:
                # ä¸ºæ¯å¯¹å®ä½“æ¨æ–­å¯èƒ½çš„å…³ç³»
                for i, entity1 in enumerate(entities):
                    for entity2 in entities[i+1:]:
                        relation = self._infer_relation_between_entities(entity1, entity2, sentence)
                        if relation:
                            triples.append(relation)
        
        return triples
    
    def _extract_entities_from_sentence(self, sentence: str) -> List[str]:
        """ä»å¥å­ä¸­æå–å®ä½“"""
        # ç®€å•çš„å®ä½“è¯†åˆ«ï¼šå¤§å†™å­—æ¯å¼€å¤´çš„è¯ã€æ•°å­—æ—¶é—´ã€ç‰¹æ®Šæ¨¡å¼
        entity_patterns = [
            r'[A-Z][a-zA-Z]+',  # å¤§å†™å¼€å¤´çš„è¯
            r'\d{4}-\d{2}-\d{2}[\s\d:]*',  # æ—¶é—´æ ¼å¼
            r'\d+[å°æ—¶å¤©åˆ†é’Ÿ]',  # æ—¶é—´é•¿åº¦
            r'[a-zA-Z]+[A-Z][a-zA-Z]*',  # é©¼å³°å‘½å
        ]
        
        entities = []
        for pattern_str in entity_patterns:
            pattern = re.compile(pattern_str)
            matches = pattern.findall(sentence)
            entities.extend(matches)
        
        return list(set(entities))  # å»é‡
    
    def _infer_relation_between_entities(self, entity1: str, entity2: str, context: str) -> Optional[TripleExtractionResult]:
        """æ¨æ–­ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»"""
        # åŸºäºä¸Šä¸‹æ–‡å…³é”®è¯æ¨æ–­å…³ç³»
        context_lower = context.lower()
        
        # æ—¶é—´å…³ç³»æ¨æ–­
        if any(keyword in context_lower for keyword in ['å¼€å§‹', 'å‘ç”Ÿ', 'start', 'begin']):
            if re.match(r'\d{4}-\d{2}-\d{2}', entity2):
                return TripleExtractionResult(
                    subject=entity1,
                    predicate="hasStartTime",
                    object=entity2,
                    confidence=0.6,
                    method="context_inference",
                    evidence=f"Context: {context[:50]}..."
                )
        
        # ä½ç½®å…³ç³»æ¨æ–­
        if any(keyword in context_lower for keyword in ['ä½äº', 'åœ¨', 'located', 'at']):
            return TripleExtractionResult(
                subject=entity1,
                predicate="locatedAt",
                object=entity2,
                confidence=0.6,
                method="context_inference",
                evidence=f"Context: {context[:50]}..."
            )
        
        return None
