"""
Âü∫‰∫éËßÑÂàôÁöÑ‰∏âÂÖÉÁªÑÊäΩÂèñÂô®
Êô∫ËÉΩÊé®Êñ≠Â±ÇÁöÑÊ†∏ÂøÉÁªÑ‰ª∂ÔºåÈÄöËøáËßÑÂàôÂíåÊ®°ÂºèËØÜÂà´Áõ¥Êé•ÊäΩÂèñ‰∏âÂÖÉÁªÑ
"""

import re
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

from ontology.managers.dynamic_schema import DynamicOntologyManager
from pipeline.enhanced_entity_inferer import EnhancedEntityTypeInferer

@dataclass
class TripleExtractionResult:
    """‰∏âÂÖÉÁªÑÊäΩÂèñÁªìÊûú"""
    subject: str
    predicate: str
    object: str
    confidence: float
    method: str
    evidence: str

class RuleBasedTripleExtractor:
    """Âü∫‰∫éËßÑÂàôÁöÑ‰∏âÂÖÉÁªÑÊäΩÂèñÂô®"""
    
    def __init__(self, ontology_manager: DynamicOntologyManager):
        self.ontology_manager = ontology_manager
        self.entity_inferer = EnhancedEntityTypeInferer()
        self.entity_inferer.ontology_manager = ontology_manager
        
        # È¢ÑÁºñËØëÁöÑÊ®°Âºè
        self._compile_patterns()
    
    def _compile_patterns(self):
        """ÁºñËØëÊäΩÂèñÊ®°Âºè"""
        self.patterns = {
            # ÂÆû‰æãÂÖ≥Á≥ªÊ®°Âºè
            'instance_patterns': [
                r'(\w+)\s+ÊòØ\s+(\w+)',
                r'(\w+)\s+Â±û‰∫é\s+(\w+)',
                r'(\w+)\s+is\s+a\s+(\w+)',
                r'(\w+)\s+is\s+an\s+(\w+)',
                r'(\w+)\s+is\s+instance\s+of\s+(\w+)',
            ],
            
            # Êó∂Èó¥ÂÖ≥Á≥ªÊ®°Âºè
            'temporal_patterns': [
                r'(\w+)\s+ÂºÄÂßãÊó∂Èó¥\s*[:Ôºö]\s*([0-9\-:\s]+)',
                r'(\w+)\s+ÁªìÊùüÊó∂Èó¥\s*[:Ôºö]\s*([0-9\-:\s]+)',
                r'(\w+)\s+ÊåÅÁª≠Êó∂Èó¥\s*[:Ôºö]\s*([0-9]+[Â∞èÊó∂Â§©ÂàÜÈíü])',
                r'(\w+)\s+ÂèëÁîüÂú®\s+([0-9\-:\s]+)',
                r'(\w+)\s+before\s+(\w+)',
                r'(\w+)\s+after\s+(\w+)',
            ],
            
            # Á©∫Èó¥ÂÖ≥Á≥ªÊ®°Âºè
            'spatial_patterns': [
                r'(\w+)\s+‰Ωç‰∫é\s+(\w+)',
                r'(\w+)\s+Âú®\s+(\w+)',
                r'(\w+)\s+located\s+at\s+(\w+)',
                r'(\w+)\s+contains\s+(\w+)',
                r'(\w+)\s+ÂåÖÂê´\s+(\w+)',
            ],
            
            # DO-DA-FÂÖ≥Á≥ªÊ®°Âºè
            'dodaf_patterns': [
                r'(\w+)\s+Êù°‰ª∂\s*[:Ôºö]\s*([^,Ôºå„ÄÇ.]+)',
                r'(\w+)\s+ÁªìÊûú\s*[:Ôºö]\s*([^,Ôºå„ÄÇ.]+)',
                r'(\w+)\s+ÂØºËá¥\s+(\w+)',
                r'(\w+)\s+causes\s+(\w+)',
                r'(\w+)\s+results\s+in\s+(\w+)',
                r'(\w+)\s+has\s+condition\s+([^,Ôºå„ÄÇ.]+)',
            ],
            
            # Êû∂ÊûÑÂÖ≥Á≥ªÊ®°Âºè
            'architecture_patterns': [
                r'(\w+)\s+ÂåÖÂê´\s+(\w+)',
                r'(\w+)\s+supports\s+(\w+)',
                r'(\w+)\s+implements\s+(\w+)',
                r'(\w+)\s+uses\s+(\w+)',
            ]
        }
        
        # ÁºñËØëÊ≠£ÂàôË°®ËææÂºè
        self.compiled_patterns = {}
        for category, patterns in self.patterns.items():
            self.compiled_patterns[category] = [re.compile(pattern, re.IGNORECASE) for pattern in patterns]
    
    def extract_triples(self, text: str) -> List[TripleExtractionResult]:
        """
        ‰ªéÊñáÊú¨‰∏≠ÊäΩÂèñ‰∏âÂÖÉÁªÑ
        
        Args:
            text: ËæìÂÖ•ÊñáÊú¨
            
        Returns:
            ‰∏âÂÖÉÁªÑÊäΩÂèñÁªìÊûúÂàóË°®
        """
        print(f"üîß ËßÑÂàôÊäΩÂèñÂô®ÂºÄÂßãÂ§ÑÁêÜÊñáÊú¨ÔºåÈïøÂ∫¶: {len(text)}")
        
        triples = []
        
        # 1. ÂÆû‰æãÂÖ≥Á≥ªÊäΩÂèñ
        instance_triples = self._extract_instance_relations(text)
        triples.extend(instance_triples)
        
        # 2. Êó∂Èó¥ÂÖ≥Á≥ªÊäΩÂèñ
        temporal_triples = self._extract_temporal_relations(text)
        triples.extend(temporal_triples)
        
        # 3. Á©∫Èó¥ÂÖ≥Á≥ªÊäΩÂèñ
        spatial_triples = self._extract_spatial_relations(text)
        triples.extend(spatial_triples)
        
        # 4. DO-DA-FÂÖ≥Á≥ªÊäΩÂèñ
        dodaf_triples = self._extract_dodaf_relations(text)
        triples.extend(dodaf_triples)
        
        # 5. Êû∂ÊûÑÂÖ≥Á≥ªÊäΩÂèñ
        arch_triples = self._extract_architecture_relations(text)
        triples.extend(arch_triples)
        
        # 6. Âü∫‰∫éÂÆû‰ΩìÊé®Êñ≠ÁöÑÂÖ≥Á≥ªÂèëÁé∞
        inferred_triples = self._infer_relations_from_entities(text)
        triples.extend(inferred_triples)
        
        print(f"üîß ËßÑÂàôÊäΩÂèñÂÆåÊàêÔºåÂÖ±ÊäΩÂèñ {len(triples)} ‰∏™‰∏âÂÖÉÁªÑ")
        
        return triples
    
    def _extract_instance_relations(self, text: str) -> List[TripleExtractionResult]:
        """ÊäΩÂèñÂÆû‰æãÂÖ≥Á≥ª"""
        triples = []
        
        for pattern in self.compiled_patterns['instance_patterns']:
            matches = pattern.findall(text)
            for match in matches:
                subject, obj = match
                
                # È™åËØÅÂÆû‰ΩìÁ±ªÂûã
                subject_type = self.entity_inferer.infer_entity_type(subject)
                object_type = self.entity_inferer.infer_entity_type(obj)
                
                if subject_type.confidence > 0.5 and object_type.confidence > 0.5:
                    triple = TripleExtractionResult(
                        subject=subject,
                        predicate="is_instance_of",
                        object=obj,
                        confidence=min(subject_type.confidence, object_type.confidence),
                        method="rule_pattern",
                        evidence=f"Pattern match: {pattern.pattern}"
                    )
                    triples.append(triple)
        
        return triples
    
    def _extract_temporal_relations(self, text: str) -> List[TripleExtractionResult]:
        """ÊäΩÂèñÊó∂Èó¥ÂÖ≥Á≥ª"""
        triples = []
        
        # ÂºÄÂßãÊó∂Èó¥Ê®°Âºè
        start_time_patterns = [
            r'(\w+)[^0-9]*ÂºÄÂßãÊó∂Èó¥[^0-9]*([0-9\-:\s]+)',
            r'(\w+)[^0-9]*ÂèëÁîüÂú®[^0-9]*([0-9\-:\s]+)',
        ]
        
        for pattern_str in start_time_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, time_str = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="hasStartTime",
                    object=time_str.strip(),
                    confidence=0.8,
                    method="temporal_pattern",
                    evidence=f"Time pattern: {pattern_str}"
                )
                triples.append(triple)
        
        # ÊåÅÁª≠Êó∂Èó¥Ê®°Âºè
        duration_patterns = [
            r'(\w+)[^0-9]*ÊåÅÁª≠Êó∂Èó¥[^0-9]*([0-9]+[Â∞èÊó∂Â§©ÂàÜÈíü])',
            r'(\w+)[^0-9]*ÊåÅÁª≠[^0-9]*([0-9]+[Â∞èÊó∂Â§©ÂàÜÈíü])',
        ]
        
        for pattern_str in duration_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, duration = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="hasDuration",
                    object=duration.strip(),
                    confidence=0.8,
                    method="temporal_pattern",
                    evidence=f"Duration pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_spatial_relations(self, text: str) -> List[TripleExtractionResult]:
        """ÊäΩÂèñÁ©∫Èó¥ÂÖ≥Á≥ª"""
        triples = []
        
        # ‰ΩçÁΩÆÂÖ≥Á≥ªÊ®°Âºè
        location_patterns = [
            r'(\w+)[^a-zA-Z]*‰Ωç‰∫é[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*Âú®[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in location_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                subject, location = match
                
                triple = TripleExtractionResult(
                    subject=subject.strip(),
                    predicate="locatedAt",
                    object=location.strip(),
                    confidence=0.8,
                    method="spatial_pattern",
                    evidence=f"Location pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_dodaf_relations(self, text: str) -> List[TripleExtractionResult]:
        """ÊäΩÂèñDO-DA-FÂÖ≥Á≥ª"""
        triples = []
        
        # Êù°‰ª∂ÂÖ≥Á≥ªÊ®°Âºè
        condition_patterns = [
            r'(\w+)[^>]*Êù°‰ª∂[^>]*[:Ôºö]\s*([^,Ôºå„ÄÇ.]+)',
            r'(\w+)[^>]*when[^>]*([^,Ôºå„ÄÇ.]+)',
        ]
        
        for pattern_str in condition_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                action, condition = match
                
                triple = TripleExtractionResult(
                    subject=action.strip(),
                    predicate="hasCondition",
                    object=condition.strip(),
                    confidence=0.7,
                    method="dodaf_pattern",
                    evidence=f"Condition pattern: {pattern_str}"
                )
                triples.append(triple)
        
        # ÁªìÊûúÂÖ≥Á≥ªÊ®°Âºè
        result_patterns = [
            r'(\w+)[^a-zA-Z]*ÁªìÊûú[^a-zA-Z]*[:Ôºö]\s*([^,Ôºå„ÄÇ.]+)',
            r'(\w+)[^a-zA-Z]*ÂØºËá¥[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*results\s+in[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in result_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                action, result = match
                
                triple = TripleExtractionResult(
                    subject=action.strip(),
                    predicate="resultsIn",
                    object=result.strip(),
                    confidence=0.7,
                    method="dodaf_pattern",
                    evidence=f"Result pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _extract_architecture_relations(self, text: str) -> List[TripleExtractionResult]:
        """ÊäΩÂèñÊû∂ÊûÑÂÖ≥Á≥ª"""
        triples = []
        
        # ÂåÖÂê´ÂÖ≥Á≥ªÊ®°Âºè
        contains_patterns = [
            r'(\w+)[^a-zA-Z]*ÂåÖÂê´[^a-zA-Z]*(\w+)',
            r'(\w+)[^a-zA-Z]*contains[^a-zA-Z]*(\w+)',
        ]
        
        for pattern_str in contains_patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE)
            matches = pattern.findall(text)
            for match in matches:
                container, contained = match
                
                triple = TripleExtractionResult(
                    subject=container.strip(),
                    predicate="contains",
                    object=contained.strip(),
                    confidence=0.7,
                    method="architecture_pattern",
                    evidence=f"Contains pattern: {pattern_str}"
                )
                triples.append(triple)
        
        return triples
    
    def _infer_relations_from_entities(self, text: str) -> List[TripleExtractionResult]:
        """Âü∫‰∫éÂÆû‰ΩìÊé®Êñ≠ÂÖ≥Á≥ª"""
        triples = []
        
        # ÁÆÄÂçïÁöÑÂÖ±Áé∞ÂÖ≥Á≥ªÊé®Êñ≠
        sentences = re.split(r'[„ÄÇ.!ÔºÅ?Ôºü]', text)
        
        for sentence in sentences:
            if len(sentence.strip()) < 10:
                continue
            
            # ÊèêÂèñÂè•Â≠ê‰∏≠ÁöÑÂÆû‰Ωì
            entities = self._extract_entities_from_sentence(sentence)
            
            if len(entities) >= 2:
                # ‰∏∫ÊØèÂØπÂÆû‰ΩìÊé®Êñ≠ÂèØËÉΩÁöÑÂÖ≥Á≥ª
                for i, entity1 in enumerate(entities):
                    for entity2 in entities[i+1:]:
                        relation = self._infer_relation_between_entities(entity1, entity2, sentence)
                        if relation:
                            triples.append(relation)
        
        return triples
    
    def _extract_entities_from_sentence(self, sentence: str) -> List[str]:
        """‰ªéÂè•Â≠ê‰∏≠ÊèêÂèñÂÆû‰Ωì"""
        # ÁÆÄÂçïÁöÑÂÆû‰ΩìËØÜÂà´ÔºöÂ§ßÂÜôÂ≠óÊØçÂºÄÂ§¥ÁöÑËØç„ÄÅÊï∞Â≠óÊó∂Èó¥„ÄÅÁâπÊÆäÊ®°Âºè
        entity_patterns = [
            r'[A-Z][a-zA-Z]+',  # Â§ßÂÜôÂºÄÂ§¥ÁöÑËØç
            r'\d{4}-\d{2}-\d{2}[\s\d:]*',  # Êó∂Èó¥Ê†ºÂºè
            r'\d+[Â∞èÊó∂Â§©ÂàÜÈíü]',  # Êó∂Èó¥ÈïøÂ∫¶
            r'[a-zA-Z]+[A-Z][a-zA-Z]*',  # È©ºÂ≥∞ÂëΩÂêç
        ]
        
        entities = []
        for pattern_str in entity_patterns:
            pattern = re.compile(pattern_str)
            matches = pattern.findall(sentence)
            entities.extend(matches)
        
        return list(set(entities))  # ÂéªÈáç
    
    def _infer_relation_between_entities(self, entity1: str, entity2: str, context: str) -> Optional[TripleExtractionResult]:
        """Êé®Êñ≠‰∏§‰∏™ÂÆû‰Ωì‰πãÈó¥ÁöÑÂÖ≥Á≥ª"""
        # Âü∫‰∫é‰∏ä‰∏ãÊñáÂÖ≥ÈîÆËØçÊé®Êñ≠ÂÖ≥Á≥ª
        context_lower = context.lower()
        
        # Êó∂Èó¥ÂÖ≥Á≥ªÊé®Êñ≠
        if any(keyword in context_lower for keyword in ['ÂºÄÂßã', 'ÂèëÁîü', 'start', 'begin']):
            if re.match(r'\d{4}-\d{2}-\d{2}', entity2):
                return TripleExtractionResult(
                    subject=entity1,
                    predicate="hasStartTime",
                    object=entity2,
                    confidence=0.6,
                    method="context_inference",
                    evidence=f"Context: {context[:50]}..."
                )
        
        # ‰ΩçÁΩÆÂÖ≥Á≥ªÊé®Êñ≠
        if any(keyword in context_lower for keyword in ['‰Ωç‰∫é', 'Âú®', 'located', 'at']):
            return TripleExtractionResult(
                subject=entity1,
                predicate="locatedAt",
                object=entity2,
                confidence=0.6,
                method="context_inference",
                evidence=f"Context: {context[:50]}..."
            )
        
        return None
