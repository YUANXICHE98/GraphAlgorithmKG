#!/usr/bin/env python3
"""
æµ‹è¯•åŸºäºSchemaçš„çŸ¥è¯†å›¾è°±æ„å»ºå™¨
"""

import sys
import os
import json
from pathlib import Path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pipeline.schema_based_kg_builder import SchemaBasedKGBuilder

def test_kg_building():
    """æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»ºåŠŸèƒ½"""
    print("ğŸ—ï¸ æµ‹è¯•åŸºäºSchemaçš„çŸ¥è¯†å›¾è°±æ„å»º")
    print("=" * 80)
    
    builder = SchemaBasedKGBuilder()
    
    # æµ‹è¯•æ–‡æ¡£åˆ—è¡¨
    test_documents = [
        {
            "path": "data/test_documents/dodaf_enterprise_architecture.json",
            "name": "é€šç”¨æ¶æ„æ–‡æ¡£",
            "expected_schema": "é€šç”¨æœ¬ä½“"
        },
        {
            "path": "data/test_documents/dodaf_spatiotemporal.json", 
            "name": "æ—¶ç©ºæè¿°æ–‡æ¡£",
            "expected_schema": "æ—¶ç©ºæœ¬ä½“"
        },
        {
            "path": "data/test_documents/pure_dodaf_structure.json",
            "name": "çº¯DO-DA-Fç»“æ„",
            "expected_schema": "æ—¶ç©ºæœ¬ä½“"
        }
    ]
    
    results = []
    
    for i, doc_info in enumerate(test_documents, 1):
        print(f"\nğŸ“„ æµ‹è¯• {i}: {doc_info['name']}")
        print("-" * 60)
        
        try:
            # æ„å»ºçŸ¥è¯†å›¾è°±
            # ç›´æ¥ä½¿ç”¨session_managerä¿å­˜ï¼Œä¸éœ€è¦outputè·¯å¾„
            kg = builder.build_knowledge_graph(
                document_path=doc_info["path"]
            )
            
            # åˆ†æç»“æœ
            print(f"\nğŸ“Š æ„å»ºç»“æœåˆ†æ:")
            print(f"   ğŸ“‹ ä½¿ç”¨Schema: {kg.metadata['schema']}")
            print(f"   ğŸ·ï¸ å®ä½“æ•°é‡: {kg.statistics['total_entities']}")
            print(f"   ğŸ”— å…³ç³»æ•°é‡: {kg.statistics['total_relations']}")
            print(f"   â±ï¸ å¤„ç†æ—¶é—´: {kg.statistics.get('processing_time', 0):.2f}s")
            print(f"   ğŸ“ˆ å¹³å‡å®ä½“ç½®ä¿¡åº¦: {kg.statistics['average_entity_confidence']:.2f}")
            print(f"   ğŸ“ˆ å¹³å‡å…³ç³»ç½®ä¿¡åº¦: {kg.statistics['average_relation_confidence']:.2f}")
            
            # å®ä½“ç±»å‹åˆ†å¸ƒ
            print(f"\nğŸ·ï¸ å®ä½“ç±»å‹åˆ†å¸ƒ:")
            for entity_type, count in kg.statistics['entity_type_distribution'].items():
                print(f"   {entity_type:<20}: {count} ä¸ª")
            
            # å…³ç³»ç±»å‹åˆ†å¸ƒ
            print(f"\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:")
            for relation_type, count in kg.statistics['relation_type_distribution'].items():
                print(f"   {relation_type:<20}: {count} ä¸ª")
            
            # æ˜¾ç¤ºéƒ¨åˆ†å®ä½“ç¤ºä¾‹
            print(f"\nğŸ“‹ å®ä½“ç¤ºä¾‹ (å‰5ä¸ª):")
            for j, entity in enumerate(kg.entities[:5], 1):
                print(f"   {j}. {entity.name} ({entity.type}) - ç½®ä¿¡åº¦: {entity.confidence:.2f}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†å…³ç³»ç¤ºä¾‹
            print(f"\nğŸ”— å…³ç³»ç¤ºä¾‹ (å‰5ä¸ª):")
            for j, relation in enumerate(kg.relations[:5], 1):
                print(f"   {j}. ({relation.subject_name}, {relation.predicate}, {relation.object_name}) - ç½®ä¿¡åº¦: {relation.confidence:.2f}")
            
            results.append({
                "document": doc_info["name"],
                "success": True,
                "entities": kg.statistics['total_entities'],
                "relations": kg.statistics['total_relations'],
                "schema": kg.metadata['schema'],
                "processing_time": kg.statistics.get('processing_time', 0)
            })
            
        except Exception as e:
            print(f"âŒ æ„å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            results.append({
                "document": doc_info["name"],
                "success": False,
                "error": str(e)
            })
    
    # æ€»ç»“æŠ¥å‘Š
    print(f"\n\nğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("=" * 80)
    
    successful_tests = [r for r in results if r["success"]]
    failed_tests = [r for r in results if not r["success"]]
    
    print(f"âœ… æˆåŠŸæµ‹è¯•: {len(successful_tests)}/{len(results)}")
    print(f"âŒ å¤±è´¥æµ‹è¯•: {len(failed_tests)}/{len(results)}")
    
    if successful_tests:
        total_entities = sum(r["entities"] for r in successful_tests)
        total_relations = sum(r["relations"] for r in successful_tests)
        avg_processing_time = sum(r["processing_time"] for r in successful_tests) / len(successful_tests)
        
        print(f"\nğŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
        print(f"   æ€»å®ä½“æ•°: {total_entities}")
        print(f"   æ€»å…³ç³»æ•°: {total_relations}")
        print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}s")
        
        print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in successful_tests:
            print(f"   {result['document']:<25}: {result['entities']} å®ä½“, {result['relations']} å…³ç³», {result['processing_time']:.2f}s")
    
    if failed_tests:
        print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
        for result in failed_tests:
            print(f"   {result['document']}: {result['error']}")
    
    return len(successful_tests) == len(results)

def test_json_format():
    """æµ‹è¯•JSONæ ¼å¼çš„æ­£ç¡®æ€§"""
    print(f"\n\nğŸ” æµ‹è¯•JSONæ ¼å¼")
    print("=" * 80)
    
    # æ£€æŸ¥ç”Ÿæˆçš„JSONæ–‡ä»¶
    # æ£€æŸ¥resultsç›®å½•ä¸‹çš„æ–‡ä»¶
    results_dir = Path("results/knowledge_graphs")
    output_files = list(results_dir.rglob("*.json"))
    
    for i, file_path in enumerate(output_files, 1):
        if os.path.exists(file_path):
            print(f"\nğŸ“„ æ£€æŸ¥æ–‡ä»¶ {i}: {file_path}")
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    kg_data = json.load(f)
                
                # éªŒè¯JSONç»“æ„
                required_keys = ['metadata', 'entities', 'relations', 'statistics']
                for key in required_keys:
                    if key not in kg_data:
                        print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")
                        continue
                
                print(f"âœ… JSONç»“æ„æ­£ç¡®")
                print(f"   å…ƒæ•°æ®å­—æ®µ: {list(kg_data['metadata'].keys())}")
                print(f"   å®ä½“æ•°é‡: {len(kg_data['entities'])}")
                print(f"   å…³ç³»æ•°é‡: {len(kg_data['relations'])}")
                print(f"   ç»Ÿè®¡å­—æ®µ: {list(kg_data['statistics'].keys())}")
                
                # æ£€æŸ¥å®ä½“ç»“æ„
                if kg_data['entities']:
                    entity = kg_data['entities'][0]
                    entity_keys = list(entity.keys())
                    print(f"   å®ä½“å­—æ®µ: {entity_keys}")
                
                # æ£€æŸ¥å…³ç³»ç»“æ„
                if kg_data['relations']:
                    relation = kg_data['relations'][0]
                    relation_keys = list(relation.keys())
                    print(f"   å…³ç³»å­—æ®µ: {relation_keys}")
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSONæ ¼å¼é”™è¯¯: {e}")
            except Exception as e:
                print(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
        else:
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª åŸºäºSchemaçš„çŸ¥è¯†å›¾è°±æ„å»ºæµ‹è¯•å¥—ä»¶")
    print("=" * 100)
    
    try:
        # æµ‹è¯•1: KGæ„å»ºåŠŸèƒ½
        success = test_kg_building()
        
        # æµ‹è¯•2: JSONæ ¼å¼éªŒè¯
        test_json_format()
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! æ•´ä½“ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¥—ä»¶æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
