"""
Schemaåˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨
ç”¨äºè®­ç»ƒæ›´å‡†ç¡®çš„Schemaæ£€æµ‹æ¨¡å‹
"""

import json
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from typing import Dict, List, Any, Optional, Tuple

from .base_trainer import BaseTrainer, TrainingConfig, TrainingResult

class SchemaClassifierTrainer(BaseTrainer):
    """Schemaåˆ†ç±»å™¨è®­ç»ƒå™¨"""
    
    def __init__(self, config: TrainingConfig):
        super().__init__(config)
        self.vectorizer = None
        self.label_encoder = {}
        self.reverse_label_encoder = {}
    
    def prepare_data(self) -> Tuple[Any, Any, Any, Any]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š åŠ è½½Schemaåˆ†ç±»è®­ç»ƒæ•°æ®...")
        
        # åŠ è½½è®­ç»ƒæ•°æ®
        with open(self.config.training_data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–æ–‡æœ¬å’Œæ ‡ç­¾
        texts = []
        labels = []
        
        for sample in data:
            texts.append(sample['text'])
            schema_path = sample['schema']
            
            # ç®€åŒ–Schemaæ ‡ç­¾
            if 'spatiotemporal' in schema_path.lower():
                label = 'spatiotemporal'
            elif 'schema_config' in schema_path.lower() or 'general' in schema_path.lower():
                label = 'general'
            else:
                label = 'mixed'
            
            labels.append(label)
        
        # åˆ›å»ºæ ‡ç­¾ç¼–ç å™¨
        unique_labels = list(set(labels))
        self.label_encoder = {label: idx for idx, label in enumerate(unique_labels)}
        self.reverse_label_encoder = {idx: label for label, idx in self.label_encoder.items()}
        
        # ç¼–ç æ ‡ç­¾
        encoded_labels = [self.label_encoder[label] for label in labels]
        
        print(f"   ğŸ“ æ–‡æœ¬æ ·æœ¬: {len(texts)}")
        print(f"   ğŸ·ï¸ æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(*np.unique(labels, return_counts=True)))}")
        
        # æ–‡æœ¬å‘é‡åŒ–
        print("ğŸ”¤ æ–‡æœ¬å‘é‡åŒ–...")
        self.vectorizer = TfidfVectorizer(
            max_features=self.config.hyperparameters.get('max_features', 5000),
            ngram_range=self.config.hyperparameters.get('ngram_range', (1, 2)),
            stop_words='english'
        )
        
        X = self.vectorizer.fit_transform(texts)
        y = np.array(encoded_labels)
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        test_size = self.config.hyperparameters.get('test_size', 0.2)
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"   ğŸ¯ è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
        print(f"   ğŸ“Š éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
        
        return X_train, y_train, X_val, y_val
    
    def build_model(self) -> RandomForestClassifier:
        """æ„å»ºéšæœºæ£®æ—åˆ†ç±»å™¨"""
        print("ğŸŒ² æ„å»ºéšæœºæ£®æ—åˆ†ç±»å™¨...")
        
        model = RandomForestClassifier(
            n_estimators=self.config.hyperparameters.get('n_estimators', 100),
            max_depth=self.config.hyperparameters.get('max_depth', 10),
            min_samples_split=self.config.hyperparameters.get('min_samples_split', 5),
            min_samples_leaf=self.config.hyperparameters.get('min_samples_leaf', 2),
            random_state=42
        )
        
        return model
    
    def train_model(self, X_train: Any, y_train: Any, X_val: Any, y_val: Any) -> TrainingResult:
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train)
        y_val_pred = self.model.predict(X_val)
        
        # è®¡ç®—å‡†ç¡®ç‡
        train_accuracy = accuracy_score(y_train, y_train_pred)
        val_accuracy = accuracy_score(y_val, y_val_pred)
        
        print(f"   ğŸ“ˆ è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.4f}")
        print(f"   ğŸ“Š éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
        
        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
        target_names = [self.reverse_label_encoder[i] for i in range(len(self.reverse_label_encoder))]
        print(classification_report(y_val, y_val_pred, target_names=target_names))
        
        # ç‰¹å¾é‡è¦æ€§
        feature_names = self.vectorizer.get_feature_names_out()
        importances = self.model.feature_importances_
        top_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)[:20]
        
        print("\nğŸ” é‡è¦ç‰¹å¾ (Top 20):")
        for feature, importance in top_features:
            print(f"   {feature}: {importance:.4f}")
        
        # æ„å»ºè®­ç»ƒç»“æœ
        result = TrainingResult(
            model_path="",  # å°†åœ¨ä¿å­˜æ—¶è®¾ç½®
            training_time=0.0,  # å°†åœ¨å¤–éƒ¨è®¾ç½®
            final_accuracy=train_accuracy,
            validation_accuracy=val_accuracy,
            training_history=[{
                'epoch': 1,
                'train_accuracy': train_accuracy,
                'val_accuracy': val_accuracy
            }],
            model_metadata={
                'model_type': 'RandomForestClassifier',
                'feature_count': X_train.shape[1],
                'label_encoder': self.label_encoder,
                'reverse_label_encoder': self.reverse_label_encoder,
                'top_features': top_features[:10]
            }
        )
        
        return result
    
    def evaluate_model(self, X_test: Any, y_test: Any) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        return {
            'accuracy': accuracy,
            'sample_count': len(y_test)
        }
    
    def predict_schema(self, text: str) -> Dict[str, Any]:
        """é¢„æµ‹æ–‡æœ¬çš„Schemaç±»å‹"""
        if self.model is None or self.vectorizer is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒæˆ–æœªåŠ è½½")
        
        # å‘é‡åŒ–æ–‡æœ¬
        X = self.vectorizer.transform([text])
        
        # é¢„æµ‹
        pred_proba = self.model.predict_proba(X)[0]
        pred_label_idx = np.argmax(pred_proba)
        pred_label = self.reverse_label_encoder[pred_label_idx]
        confidence = pred_proba[pred_label_idx]
        
        # æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
        all_probabilities = {
            self.reverse_label_encoder[i]: prob 
            for i, prob in enumerate(pred_proba)
        }
        
        return {
            'predicted_schema': pred_label,
            'confidence': confidence,
            'all_probabilities': all_probabilities
        }

def create_schema_classifier_config(
    training_data_path: str,
    output_model_path: str = "training/models/schema_classifier/latest.pkl",
    hyperparameters: Dict[str, Any] = None
) -> TrainingConfig:
    """åˆ›å»ºSchemaåˆ†ç±»å™¨è®­ç»ƒé…ç½®"""
    
    if hyperparameters is None:
        hyperparameters = {
            'max_features': 5000,
            'ngram_range': (1, 2),
            'n_estimators': 100,
            'max_depth': 10,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'test_size': 0.2
        }
    
    return TrainingConfig(
        model_name="Schemaåˆ†ç±»å™¨",
        model_type="schema_classifier",
        training_data_path=training_data_path,
        validation_data_path=None,
        output_model_path=output_model_path,
        hyperparameters=hyperparameters,
        training_metadata={
            'description': 'åŸºäºTF-IDFå’Œéšæœºæ£®æ—çš„Schemaåˆ†ç±»å™¨',
            'input_format': 'text',
            'output_format': 'schema_type',
            'supported_schemas': ['general', 'spatiotemporal', 'mixed']
        }
    )

def train_schema_classifier(
    training_data_path: str = None,
    output_model_path: str = "training/models/schema_classifier/latest.pkl",
    hyperparameters: Dict[str, Any] = None
) -> TrainingResult:
    """è®­ç»ƒSchemaåˆ†ç±»å™¨çš„ä¾¿æ·å‡½æ•°"""
    
    # å¦‚æœæ²¡æœ‰æä¾›è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œè‡ªåŠ¨æ”¶é›†
    if training_data_path is None:
        from .base_trainer import training_data_manager
        training_data_path = training_data_manager.collect_schema_training_data()
    
    # åˆ›å»ºé…ç½®
    config = create_schema_classifier_config(
        training_data_path=training_data_path,
        output_model_path=output_model_path,
        hyperparameters=hyperparameters
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
    trainer = SchemaClassifierTrainer(config)
    result = trainer.run_full_training()
    
    return result

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šè®­ç»ƒSchemaåˆ†ç±»å™¨
    result = train_schema_classifier()
    print(f"ğŸ‰ Schemaåˆ†ç±»å™¨è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {result.model_path}")
    print(f"ğŸ“ˆ éªŒè¯å‡†ç¡®ç‡: {result.validation_accuracy:.4f}")
